defaults:

  logdir: ~/logdir/{timestamp}
  replica: 0
  replicas: 1
  method: name
  task: dummy_disc
  seed: 0
  script: train
  batch_size: 16
  batch_length: 64
  report_length: 32
  consec_train: 1
  consec_report: 1
  replay_context: 1
  random_agent: False
  clock_addr: ''
  clock_port: ''
  ipv6: False
  errfile: False

  logger:
    outputs: [jsonl, scope]
    filter: 'score|length|fps|ratio|train/loss/|train/rand/'
    timer: True
    fps: 15
    user: ''

  env:
    # Added default nested observation.type so overrides like
    # highway_merge_rgb can safely modify env.gym.config.observation.type.
    gym: {imports: [gymnasium], obs_key: image, act_key: action, render_mode: none, record_video: False, video_dir: '', config: {observation: {type: kinematics}, ego_speed: 30.0, other_vehicles_speed_range: [29, 32], merging_vehicle_speed: 20.0, merging_vehicle_target_speed: 30.0, speed_multiplier: 1.0, reward_speed_range: [20, 30]}}
    dm: {size: [64, 64]}
    dummy: {}

  replay:
    size: 5e6
    online: True
    fracs: {uniform: 1.0, priority: 0.0, recency: 0.0}
    prio: {exponent: 0.8, maxfrac: 0.5, initial: inf, zero_on_sample: True}
    priosignal: model
    recexp: 1.0
    chunksize: 1024

  run:
    steps: 1e10
    duration: 0
    train_ratio: 32.0
    log_every: 120
    report_every: 300
    save_every: 900
    envs: 16
    eval_envs: 4
    eval_eps: 1
    report_batches: 1
    from_checkpoint: ''
    episode_timeout: 180
    actor_addr: 'localhost:{auto}'
    replay_addr: 'localhost:{auto}'
    logger_addr: 'localhost:{auto}'
    actor_batch: -1
    actor_threads: 1
    agent_process: False
    remote_replay: False
    remote_envs: False
    usage: {psutil: True, nvsmi: True, gputil: False, malloc: False, gc: False}
    debug: True

  jax:
    platform: cuda
    compute_dtype: bfloat16
    policy_devices: [0]
    train_devices: [0]
    mock_devices: 0
    prealloc: True
    jit: True
    debug: False
    expect_devices: 0
    enable_policy: True
    coordinator_address: ''

  agent:
    loss_scales: {rec: 1.0, rew: 1.0, con: 1.0, dyn: 1.0, rep: 0.1, policy: 1.0, value: 1.0, repval: 0.3}
    opt: {lr: 4e-5, agc: 0.3, eps: 1e-20, beta1: 0.9, beta2: 0.999, momentum: True, wd: 0.0, schedule: const, warmup: 1000, anneal: 0}
    ac_grads: False
    dyn:
      typ: rssm
      rssm: {deter: 8192, hidden: 1024, stoch: 32, classes: 64, act: silu, norm: rms, unimix: 0.01, outscale: 1.0, winit: trunc_normal_in, imglayers: 2, obslayers: 1, dynlayers: 1, absolute: False, blocks: 8, free_nats: 1.0}
    enc:
      typ: simple
      simple: {depth: 64, mults: [2, 3, 4, 4], layers: 3, units: 1024, act: silu, norm: rms, winit: trunc_normal_in, symlog: True, outer: False, kernel: 5, strided: False}
    dec:
      typ: simple
      simple: {depth: 64, mults: [2, 3, 4, 4], layers: 3, units: 1024, act: silu, norm: rms, outscale: 1.0, winit: trunc_normal_in, outer: False, kernel: 5, bspace: 8, strided: False}
    rewhead: {layers: 1, units: 1024, act: silu, norm: rms, output: symexp_twohot, outscale: 0.0, winit: trunc_normal_in, bins: 255}
    conhead: {layers: 1, units: 1024, act: silu, norm: rms, output: binary, outscale: 1.0, winit: trunc_normal_in}
    policy: {layers: 3, units: 1024, act: silu, norm: rms, minstd: 0.1, maxstd: 1.0, outscale: 0.01, unimix: 0.01, winit: trunc_normal_in}
    value: {layers: 3, units: 1024, act: silu, norm: rms, output: symexp_twohot, outscale: 0.0, winit: trunc_normal_in, bins: 255}
    policy_dist_disc: categorical
    policy_dist_cont: bounded_normal
    imag_last: 0
    imag_length: 15
    horizon: 333
    contdisc: True
    imag_loss: {slowtar: False, lam: 0.95, actent: 3e-4, slowreg: 1.0}
    repl_loss: {slowtar: False, lam: 0.95, slowreg: 1.0}
    slowvalue: {rate: 0.02, every: 1}
    retnorm: {impl: perc, rate: 0.01, limit: 1.0, perclo: 5.0, perchi: 95.0, debias: False}
    valnorm: {impl: none, rate: 0.01, limit: 1e-8}
    advnorm: {impl: none, rate: 0.01, limit: 1e-8}
    reward_grad: True
    repval_loss: True
    repval_grad: True
    report: True
    report_gradnorms: False

size1m: &size1m
  .*\.rssm: {deter: 512, hidden: 64, classes: 4}
  .*\.depth: 4
  .*\.units: 64

size12m: &size12m
  .*\.rssm: {deter: 2048, hidden: 256, classes: 16}
  .*\.depth: 16
  .*\.units: 256

size25m: &size25m
  .*\.rssm: {deter: 3072, hidden: 384, classes: 24}
  .*\.depth: 24
  .*\.units: 384

size50m: &size50m
  .*\.rssm: {deter: 4096, hidden: 512, classes: 32}
  .*\.depth: 32
  .*\.units: 512

size100m: &size100m
  .*\.rssm: {deter: 6144, hidden: 768, classes: 48}
  .*\.depth: 48
  .*\.units: 768

size200m: &size200m
  .*\.rssm: {deter: 8192, hidden: 1024, classes: 64}
  .*\.depth: 64
  .*\.units: 1024

size400m: &size400m
  .*\.rssm: {deter: 12288, hidden: 1536, classes: 96}
  .*\.depth: 96
  .*\.units: 1536

debug:
  batch_size: 8
  batch_length: 10
  report_length: 5
  jax: {platform: cpu, debug: True, prealloc: False}
  run: {envs: 4, report_every: 10, log_every: 5, save_every: 15, train_ratio: 8, debug: True}
  replay.size: 1e4
  agent:
    .*\.bins: 5
    .*\.layers: 1
    .*\.units: 8
    .*\.stoch: 2
    .*\.classes: 4
    .*\.deter: 8
    .*\.hidden: 3
    .*\.blocks: 4
    .*\.depth: 2

highway_merge:
  task: gym_merge-v0
  env.gym:
    imports: [highway_env]
    obs_key: observation
    act_key: action
  run:
    episode_timeout: 60

highway_merge_rgb:
  task: gym_merge-v0
  env.gym:
    imports: [highway_env]
    obs_key: observation
    act_key: action
    render_mode: human
    config:
      observation:
        type: Kinematics
  run:
    episode_timeout: 60

# Fast merge environment with configurable speeds
highway_merge_fast:
  task: gym_fast-merge-v0
  env.gym:
    imports: [highway_env, embodied.envs.fast_merge]
    obs_key: observation
    act_key: action
    render_mode: human
    config:
      observation:
        type: Kinematics
      # Speed configuration (m/s) - default is ~30 m/s = ~108 km/h
      # Increase these for faster driving
      ego_speed: 35.0                        # Ego vehicle initial speed
      other_vehicles_speed_range: [33, 38]   # Other vehicles speed range
      merging_vehicle_speed: 25.0            # Merging vehicle initial speed  
      merging_vehicle_target_speed: 35.0     # Merging vehicle target speed
      reward_speed_range: [30, 40]           # Speed range for rewards
      # Or use multiplier to scale all speeds (e.g., 1.2 = 20% faster)
      # speed_multiplier: 1.0
  run:
    episode_timeout: 60

# Very fast merge - 40% faster than default
highway_merge_veryfast:
  task: gym_fast-merge-v0
  env.gym:
    imports: [highway_env, embodied.envs.fast_merge]
    obs_key: observation
    act_key: action
    render_mode: human
    config:
      observation:
        type: Kinematics
      speed_multiplier: 1.4
      reward_speed_range: [28, 42]
  run:
    episode_timeout: 45

# ============================================================================
# HIGHWAY ENVIRONMENT - High-speed highway driving with traffic
# ============================================================================
highway:
  task: gym_highway-v0
  env.gym:
    imports: [highway_env]
    obs_key: observation
    act_key: action
    render_mode: human
    config:
      observation:
        type: Kinematics
      lanes_count: 4
      vehicles_count: 50
      duration: 40
  run:
    episode_timeout: 60

highway_fast:
  task: gym_highway-v0
  env.gym:
    imports: [highway_env]
    obs_key: observation
    act_key: action
    render_mode: human
    config:
      observation:
        type: Kinematics
      lanes_count: 4
      vehicles_count: 50
      duration: 40
      reward_speed_range: [25, 35]
  run:
    episode_timeout: 60

# ============================================================================
# ROUNDABOUT ENVIRONMENT - Navigate through a roundabout
# ============================================================================
roundabout:
  task: gym_roundabout-v0
  env.gym:
    imports: [highway_env]
    obs_key: observation
    act_key: action
    render_mode: human
    config:
      observation:
        type: Kinematics
  run:
    episode_timeout: 60

# ============================================================================
# PARKING ENVIRONMENT - Parallel parking task (continuous control)
# ============================================================================
parking:
  task: gym_parking-v0
  env.gym:
    imports: [highway_env]
    obs_key: observation
    act_key: action
    render_mode: human
    config:
      observation:
        type: KinematicsGoal
  run:
    episode_timeout: 120

# ============================================================================
# INTERSECTION ENVIRONMENT - Navigate through an intersection
# ============================================================================
intersection:
  task: gym_intersection-v0
  env.gym:
    imports: [highway_env]
    obs_key: observation
    act_key: action
    render_mode: human
    config:
      observation:
        type: Kinematics
  run:
    episode_timeout: 60

# ============================================================================
# RACETRACK ENVIRONMENT - Drive on a racetrack (continuous control)
# ============================================================================
racetrack:
  task: gym_racetrack-v0
  env.gym:
    imports: [highway_env]
    obs_key: observation
    act_key: action
    render_mode: human
    config:
      observation:
        type: Kinematics
  run:
    episode_timeout: 90

